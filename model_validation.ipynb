{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import\n",
    "from decision_tree import DecisionTree as DT\n",
    "from decision_tree_for_forest import DecisionTree as DT2\n",
    "from random_forest import RandomForest\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data\n",
    "data=pd.read_csv('coffee_data.csv')\n",
    "# data=pd.read_csv('wine_dataset_small.csv')\n",
    "np_array=data.to_numpy()\n",
    "X, y = np_array[:, :-1], np_array[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForest(\n",
    "    n_estimators=20, \n",
    "    max_depth=7, \n",
    "    criterion=\"gini\", \n",
    "    max_features=\"log2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold Cross-Validation Accuracies: [0.7380952380952381, 0.8809523809523809, 0.8095238095238095, 0.8571428571428571, 0.7857142857142857, 0.8333333333333334, 0.7619047619047619, 0.8333333333333334, 0.8571428571428571, 0.7560975609756098]\n",
      "Average Cross-Validation Accuracy: 0.8113240418118467\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "# Create StratifiedKFold instance (to keep class distribution in all folds)\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=0)\n",
    "\n",
    "# To store accuracy for each fold\n",
    "accuracies = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, val_index in skf.split(X, y):\n",
    "    X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "    y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "\n",
    "    # Fit the RandomForest on the current fold's training data\n",
    "    rf.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = rf.predict(X_val_fold)\n",
    "    \n",
    "    # Calculate accuracy for this fold\n",
    "    fold_accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
    "    \n",
    "    # Append accuracy to list\n",
    "    accuracies.append(fold_accuracy)\n",
    "\n",
    "# Calculate the average accuracy across all folds\n",
    "avg_accuracy = np.mean(accuracies)\n",
    "\n",
    "print(f\"K-Fold Cross-Validation Accuracies: {accuracies}\")\n",
    "print(f\"Average Cross-Validation Accuracy: {avg_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DecisionTree.__init__() got an unexpected keyword argument 'max_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m y_train_fold, y_val_fold \u001b[38;5;241m=\u001b[39m y[train_index], y[val_index]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Initialize and train the model\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m dt \u001b[38;5;241m=\u001b[39m \u001b[43mDT2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_depth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_features\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m dt\u001b[38;5;241m.\u001b[39mfit(X_train_fold, y_train_fold)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Evaluate on validation fold\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: DecisionTree.__init__() got an unexpected keyword argument 'max_features'"
     ]
    }
   ],
   "source": [
    "# decision_tree_params = {\n",
    "#     'max_depth': [None, 3, 5, 7, 10, 12, 15, 17, 20],\n",
    "#     'criterion': ['gini', 'entropy'],\n",
    "#     'max_features': [None, 'sqrt', 'log2', 'two']\n",
    "# }\n",
    "\n",
    "decision_tree_params = {\n",
    "    'max_depth': [None, 1, 2, 3, 4],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_features': [None, 'sqrt', 'log2', 'two', 'minus_one']\n",
    "}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "\n",
    "for max_depth, criterion, max_features in itertools.product(\n",
    "    decision_tree_params['max_depth'],\n",
    "    decision_tree_params['criterion'],\n",
    "    decision_tree_params['max_features']\n",
    "):\n",
    "    accuracies = []\n",
    "    for train_index, val_index in skf.split(X, y):\n",
    "        X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "        y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "        \n",
    "        # Initialize and train the model\n",
    "        dt = DT2(\n",
    "            max_depth=max_depth,\n",
    "            criterion=criterion,\n",
    "            max_features=max_features\n",
    "        )\n",
    "        dt.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Evaluate on validation fold\n",
    "        y_pred = dt.predict(X_val_fold)\n",
    "        accuracy = np.mean(y_pred == y_val_fold)\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    \n",
    "    if avg_accuracy > best_accuracy:\n",
    "        best_accuracy = avg_accuracy\n",
    "        best_params = {\n",
    "            'max_depth': max_depth,\n",
    "            'criterion': criterion,\n",
    "            'max_features': max_features\n",
    "        }\n",
    "\n",
    "print(\"Best Decision Tree parameters:\", best_params)\n",
    "print(\"Cross-Validation Accuracy:\", best_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
