{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import\n",
    "from decision_tree import DecisionTree as DT\n",
    "from decision_tree_for_forest import DecisionTree as DT2\n",
    "from random_forest import RandomForest\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "\n",
    "#Heatmap?\n",
    "#Finne beste model med k-fold\n",
    "#Trene med all dataen\n",
    "#Så få resultatet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data\n",
    "#data=pd.read_csv('coffee_data.csv')\n",
    "data=pd.read_csv('wine_dataset_small.csv')\n",
    "np_array=data.to_numpy()\n",
    "X, y = np_array[:, :-1], np_array[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(object, n_estimators=None, max_depth=None, criterion=None, max_features=None):\n",
    "    k = 5\n",
    "    # Create StratifiedKFold instance (to keep class distribution in all folds)\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=0)\n",
    "\n",
    "    params={'n_estimators' : n_estimators, 'max_depth': max_depth , 'criterion':criterion, 'max_features':max_features}\n",
    "\n",
    "    best_accuracy=0\n",
    "    best_params=None\n",
    "\n",
    "\n",
    "            \n",
    "    if object=='tree':\n",
    "        for max_depth, criterion in itertools.product(\n",
    "            params['max_depth'],\n",
    "            params['criterion'],\n",
    "        ):\n",
    "            accuracies = []\n",
    "            for train_index, val_index in skf.split(X, y):\n",
    "                X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "                y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "                dt = DT2(\n",
    "                    max_depth=max_depth,\n",
    "                    criterion=criterion,\n",
    "                )\n",
    "                dt.fit(X_train_fold, y_train_fold)\n",
    "            \n",
    "            # Evaluate on validation fold\n",
    "                y_pred = dt.predict(X_val_fold)\n",
    "                accuracy = np.mean(y_pred == y_val_fold)\n",
    "                accuracies.append(accuracy)\n",
    "        \n",
    "            avg_accuracy = np.mean(accuracies)\n",
    "\n",
    "        if avg_accuracy > best_accuracy:\n",
    "            best_accuracy = avg_accuracy\n",
    "            best_params = {\n",
    "                'max_depth': max_depth,\n",
    "                'criterion': criterion,\n",
    "                'max_features': max_features\n",
    "            }\n",
    "\n",
    "    if object=='forest':\n",
    "        for n_estimators, max_depth, criterion, max_features in itertools.product(\n",
    "            params['n_estimators'],\n",
    "            params['max_depth'],\n",
    "            params['criterion'],\n",
    "            params['max_features']\n",
    "        ):\n",
    "            accuracies = []\n",
    "            for train_index, val_index in skf.split(X, y):\n",
    "                X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "                y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "                    # Initialize and train the RandomForest model\n",
    "                rf = RandomForest(\n",
    "                    n_estimators=n_estimators,\n",
    "                    max_depth=max_depth,\n",
    "                    criterion=criterion,\n",
    "                    max_features=max_features\n",
    "                )\n",
    "                rf.fit(X_train_fold, y_train_fold)\n",
    "                \n",
    "                # Evaluate on validation fold\n",
    "                y_pred = rf.predict(X_val_fold)\n",
    "                accuracy = np.mean(y_pred == y_val_fold)\n",
    "                accuracies.append(accuracy)\n",
    "            \n",
    "            avg_accuracy = np.mean(accuracies)\n",
    "    \n",
    "    # Store best parameters\n",
    "        if avg_accuracy > best_accuracy:\n",
    "            best_accuracy = avg_accuracy\n",
    "            best_params = {\n",
    "                'n_estimators': n_estimators,\n",
    "                'max_depth': max_depth,\n",
    "                'criterion': criterion,\n",
    "                'max_features': max_features\n",
    "            }\n",
    "    return best_params, best_accuracy\n",
    "        #best acc er cross val acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search2(object, n_estimators=None, max_depth=None, criterion=None, max_features=None):\n",
    "    k = 5\n",
    "    # Create StratifiedKFold instance (to keep class distribution in all folds)\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=0)\n",
    "\n",
    "    params={'n_estimators' : n_estimators, 'max_depth': max_depth , 'criterion':criterion, 'max_features':max_features}\n",
    "\n",
    "    best_accuracy=0\n",
    "    best_params=None\n",
    "\n",
    "\n",
    "            \n",
    "    if object=='tree':\n",
    "        for max_depth, criterion in itertools.product(\n",
    "            params['max_depth'],\n",
    "            params['criterion'],\n",
    "        ):\n",
    "            accuracies = []\n",
    "            for train_index, val_index in skf.split(X, y):\n",
    "                X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "                y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "                dt = DTC(\n",
    "                    max_depth=max_depth,\n",
    "                    criterion=criterion,\n",
    "                )\n",
    "                dt.fit(X_train_fold, y_train_fold)\n",
    "            \n",
    "            # Evaluate on validation fold\n",
    "                y_pred = dt.predict(X_val_fold)\n",
    "                accuracy = np.mean(y_pred == y_val_fold)\n",
    "                accuracies.append(accuracy)\n",
    "        \n",
    "            avg_accuracy = np.mean(accuracies)\n",
    "\n",
    "        if avg_accuracy > best_accuracy:\n",
    "            best_accuracy = avg_accuracy\n",
    "            best_params = {\n",
    "                'max_depth': max_depth,\n",
    "                'criterion': criterion,\n",
    "                'max_features': max_features\n",
    "            }\n",
    "\n",
    "    if object=='forest':\n",
    "        for n_estimators, max_depth, criterion, max_features in itertools.product(\n",
    "            params['n_estimators'],\n",
    "            params['max_depth'],\n",
    "            params['criterion'],\n",
    "            params['max_features']\n",
    "        ):\n",
    "            accuracies = []\n",
    "            for train_index, val_index in skf.split(X, y):\n",
    "                X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "                y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "                    # Initialize and train the RandomForest model\n",
    "                rf = RFC(\n",
    "                    n_estimators=n_estimators,\n",
    "                    max_depth=max_depth,\n",
    "                    criterion=criterion,\n",
    "                    max_features=max_features\n",
    "                )\n",
    "                rf.fit(X_train_fold, y_train_fold)\n",
    "                \n",
    "                # Evaluate on validation fold\n",
    "                y_pred = rf.predict(X_val_fold)\n",
    "                accuracy = np.mean(y_pred == y_val_fold)\n",
    "                accuracies.append(accuracy)\n",
    "            \n",
    "            avg_accuracy = np.mean(accuracies)\n",
    "    \n",
    "    # Store best parameters\n",
    "        if avg_accuracy > best_accuracy:\n",
    "            best_accuracy = avg_accuracy\n",
    "            best_params = {\n",
    "                'n_estimators': n_estimators,\n",
    "                'max_depth': max_depth,\n",
    "                'criterion': criterion,\n",
    "                'max_features': max_features\n",
    "            }\n",
    "    return best_params, best_accuracy\n",
    "        #best acc er cross val acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'max_depth': 10, 'criterion': 'entropy', 'max_features': None}, 0.8320000000000001)\n",
      "({'n_estimators': 5, 'max_depth': 10, 'criterion': 'gini', 'max_features': 'sqrt'}, 0.858)\n",
      "({'max_depth': 10, 'criterion': 'entropy', 'max_features': None}, 0.8299999999999998)\n",
      "({'n_estimators': 5, 'max_depth': 10, 'criterion': 'gini', 'max_features': 'sqrt'}, 0.8579999999999999)\n"
     ]
    }
   ],
   "source": [
    "print(grid_search('tree', max_depth=[2, 4, 6, 8, 10], criterion=['entropy', 'gini']))\n",
    "#print(grid_search('forest', [5], [10], ['gini'], ['sqrt']))\n",
    "print(grid_search2('tree', max_depth=[2, 4, 6, 8, 10], criterion=['entropy', 'gini']))\n",
    "#print(grid_search2('forest', [5], [10], ['gini'], ['sqrt']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
